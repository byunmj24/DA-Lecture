{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"20211229_glaucoma_classification.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOM9EG0ncqxOiErUF48vf/G"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 모듈 임포트"],"metadata":{"id":"gAD_ro1p4kS8"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import tensorflow as tf"],"metadata":{"id":"nCSAoEJx7bVn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"id":"mIP-eoYg46Ig"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 데이터 준비"],"metadata":{"id":"8eGOVvel9VLW"}},{"cell_type":"code","source":["!ls -al '/content/gdrive/MyDrive/빅데이터 분석가 양성 과정 자료실/딥러닝/dataset/'"],"metadata":{"id":"qVX8faBd5aHU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cp '/content/gdrive/MyDrive/빅데이터 분석가 양성 과정 자료실/딥러닝/dataset/glaucoma.zip' ./"],"metadata":{"id":"61bjZHH88gdu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!unzip glaucoma.zip"],"metadata":{"id":"-YKRIASD8k_u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# glaucoma directory 에 없는 경우\n","# !mkdir glaucoma\n","# !mv train glaucoma/\n","# !mv valid glaucoma/\n","# !mv test glaucoma/"],"metadata":{"id":"o8JFUx-e9kaE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 전이학습 시도"],"metadata":{"id":"6_-BhZ6I9g1m"}},{"cell_type":"code","source":["import os\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","from tensorflow import keras\n","from tensorflow.keras import optimizers\n","from tensorflow.keras import models\n","from tensorflow.keras import layers\n","from tensorflow.keras import optimizers\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dropout, Flatten, Dense, BatchNormalization\n","from tensorflow.keras import Model\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.preprocessing.image import load_img\n","from tensorflow.keras.preprocessing.image import img_to_array\n","\n","from tensorflow.keras.applications import efficientnet\n","from tensorflow.keras.applications import EfficientNetB2\n","\n","preprocessor = efficientnet.preprocess_input\n","\n","conv_layers = EfficientNetB2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","conv_layers.trainable = False\n","\n","model = keras.Sequential()\n","\n","model.add(conv_layers)\n","model.add(Flatten())\n","model.add(Dense(256, activation='relu'))\n","model.add(Dense(256, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dense(3, activation='softmax'))\n","\n","model.compile(loss='sparse_categorical_crossentropy', optimizer=\"RMSprop\", metrics=['acc'])\n","model.summary()\n","\n","BATCH_SIZE = 64\n","\n","train_data_generator = ImageDataGenerator(\n","      rotation_range=10,\n","      width_shift_range=0.1,\n","      height_shift_range=0.1,\n","      horizontal_flip=True,\n","      vertical_flip=False,\n","      preprocessing_function=preprocessor\n",").flow_from_directory(\n","      \"glaucoma/train\",\n","      target_size=(224,224),\n","      batch_size=BATCH_SIZE,\n","      class_mode='sparse'\n",")\n","\n","valid_data_generator = ImageDataGenerator(\n","      preprocessing_function=preprocessor\n",").flow_from_directory(\n","      \"glaucoma/valid\",\n","      target_size=(224,224),\n","      batch_size=BATCH_SIZE,\n","      class_mode='sparse'\n",")\n","\n","test_data_generator = ImageDataGenerator(\n","      preprocessing_function=preprocessor\n",").flow_from_directory(\n","      \"glaucoma/test\",\n","      target_size=(224,224),\n","      batch_size=BATCH_SIZE,\n","      class_mode='sparse'\n",")\n","\n","\n","history = model.fit(\n","      train_data_generator,\n","      validation_data=valid_data_generator,\n","      epochs=10\n",")\n","\n","\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.show()\n","\n","\n","loss, acc = model.evaluate(test_data_generator)\n","print(\"loss=\", loss)\n","print(\"acc=\", acc)\n","\n","\n","\n","batch_x, batch_y = test_data_generator.next()\n","y_ = model.predict(batch_x)\n","predicted = np.argmax(y_, axis=-1)\n","\n","plt.plot(batch_y[:100], \"o\")\n","plt.plot(predicted[:100], '.')\n","plt.show()\n","\n","\n","custom_labels = list(test_data_generator.class_indices.keys())\n","print(\"label category index =\", batch_y[0])\n","print(\"predicted category index =\", predicted[0])\n","print(\"predicted category name =\", custom_labels[predicted[0]])\n"],"metadata":{"id":"wRHGlt7C48wU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 전이학습 + Conv도 학습\n"],"metadata":{"id":"BskT9kykBjGb"}},{"cell_type":"code","source":["\n","preprocessor = efficientnet.preprocess_input\n","\n","conv_layers = EfficientNetB2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","conv_layers.trainable = True      # <-----\n","\n","model = keras.Sequential()\n","\n","model.add(conv_layers)\n","model.add(Flatten())\n","model.add(Dense(256, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dense(3, activation='softmax'))\n","\n","model.compile(loss='sparse_categorical_crossentropy', optimizer=\"RMSprop\", metrics=['acc'])\n","model.summary()\n","\n","BATCH_SIZE = 64\n","\n","train_data_generator = ImageDataGenerator(\n","      rotation_range=10,\n","      width_shift_range=0.1,\n","      height_shift_range=0.1,\n","      horizontal_flip=True,\n","      vertical_flip=False,\n","      preprocessing_function=preprocessor\n",").flow_from_directory(\n","      \"glaucoma/train\",\n","      target_size=(224,224),\n","      batch_size=BATCH_SIZE,\n","      class_mode='sparse'\n",")\n","\n","valid_data_generator = ImageDataGenerator(\n","      preprocessing_function=preprocessor\n",").flow_from_directory(\n","      \"glaucoma/valid\",\n","      target_size=(224,224),\n","      batch_size=BATCH_SIZE,\n","      class_mode='sparse'\n",")\n","\n","test_data_generator = ImageDataGenerator(\n","      preprocessing_function=preprocessor\n",").flow_from_directory(\n","      \"glaucoma/test\",\n","      target_size=(224,224),\n","      batch_size=BATCH_SIZE,\n","      class_mode='sparse'\n",")\n","\n","\n","history = model.fit(\n","      train_data_generator,\n","      validation_data=valid_data_generator,\n","      epochs=10\n",")\n","\n","\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.show()\n","\n","\n","loss, acc = model.evaluate(test_data_generator)\n","print(\"loss=\", loss)\n","print(\"acc=\", acc)\n","\n","\n","\n","batch_x, batch_y = test_data_generator.next()\n","y_ = model.predict(batch_x)\n","predicted = np.argmax(y_, axis=-1)\n","\n","plt.plot(batch_y[:100], \"o\")\n","plt.plot(predicted[:100], '.')\n","plt.show()\n","\n","\n","custom_labels = list(test_data_generator.class_indices.keys())\n","print(\"label category index =\", batch_y[0])\n","print(\"predicted category index =\", predicted[0])\n","print(\"predicted category name =\", custom_labels[predicted[0]])\n"],"metadata":{"id":"gJfn1T2G5kNj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# vanila CNN으로"],"metadata":{"id":"ZUbO9jOqC6Io"}},{"cell_type":"code","source":["from tensorflow.keras.layers import Dropout, Flatten, Dense, BatchNormalization, Conv2D, MaxPooling2D, Input\n","from tensorflow.keras import Model\n","\n","preprocessor = efficientnet.preprocess_input\n","\n","conv_layers = EfficientNetB2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","conv_layers.trainable = False\n","\n","model = keras.Sequential()\n","\n","# model.add(conv_layers)\n","model.add(Input((224,224,3)))                        # <-----\n","model.add(Conv2D(64, (3,3), padding='same'))\n","model.add(Conv2D(64, (3,3), padding='same'))\n","model.add(MaxPooling2D())\n","model.add(Conv2D(128, (3,3), padding='same'))\n","model.add(Conv2D(128, (3,3), padding='same'))\n","model.add(MaxPooling2D())\n","model.add(Conv2D(256, (3,3), padding='same'))\n","model.add(Conv2D(256, (3,3), padding='same'))\n","model.add(Conv2D(256, (3,3), padding='same'))\n","model.add(MaxPooling2D())\n","model.add(Conv2D(512, (3,3), padding='same'))\n","model.add(Conv2D(512, (3,3), padding='same'))\n","model.add(Conv2D(512, (3,3), padding='same'))\n","model.add(MaxPooling2D())\n","model.add(Conv2D(512, (3,3), padding='same'))\n","model.add(Conv2D(512, (3,3), padding='same'))\n","model.add(Conv2D(512, (3,3), padding='same'))\n","model.add(MaxPooling2D())                             # <-----\n","model.add(Flatten())\n","model.add(Dense(256, activation='relu'))\n","model.add(Dense(256, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dense(3, activation='softmax'))\n","\n","model.compile(loss='sparse_categorical_crossentropy', optimizer=\"RMSprop\", metrics=['acc'])\n","model.summary()\n","\n","BATCH_SIZE = 64\n","\n","train_data_generator = ImageDataGenerator(\n","      rotation_range=10,\n","      width_shift_range=0.1,\n","      height_shift_range=0.1,\n","      horizontal_flip=True,\n","      vertical_flip=False,\n","      preprocessing_function=preprocessor\n",").flow_from_directory(\n","      \"glaucoma/train\",\n","      target_size=(224,224),\n","      batch_size=BATCH_SIZE,\n","      class_mode='sparse'\n",")\n","\n","valid_data_generator = ImageDataGenerator(\n","      preprocessing_function=preprocessor\n",").flow_from_directory(\n","      \"glaucoma/valid\",\n","      target_size=(224,224),\n","      batch_size=BATCH_SIZE,\n","      class_mode='sparse'\n",")\n","\n","test_data_generator = ImageDataGenerator(\n","      preprocessing_function=preprocessor\n",").flow_from_directory(\n","      \"glaucoma/test\",\n","      target_size=(224,224),\n","      batch_size=BATCH_SIZE,\n","      class_mode='sparse'\n",")\n","\n","\n","history = model.fit(\n","      train_data_generator,\n","      validation_data=valid_data_generator,\n","      epochs=10\n",")\n","\n","\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.show()\n","\n","\n","loss, acc = model.evaluate(test_data_generator)\n","print(\"loss=\", loss)\n","print(\"acc=\", acc)\n","\n","\n","\n","batch_x, batch_y = test_data_generator.next()\n","y_ = model.predict(batch_x)\n","predicted = np.argmax(y_, axis=-1)\n","\n","plt.plot(batch_y[:100], \"o\")\n","plt.plot(predicted[:100], '.')\n","plt.show()\n","\n","\n","custom_labels = list(test_data_generator.class_indices.keys())\n","print(\"label category index =\", batch_y[0])\n","print(\"predicted category index =\", predicted[0])\n","print(\"predicted category name =\", custom_labels[predicted[0]])\n"],"metadata":{"id":"ODeeFYDJB5ak"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Learning rate 작게"],"metadata":{"id":"joo5XZDHDZzw"}},{"cell_type":"code","source":["from tensorflow.keras.layers import Dropout, Flatten, Dense, BatchNormalization, Conv2D, MaxPooling2D, Input\n","from tensorflow.keras import Model\n","\n","preprocessor = efficientnet.preprocess_input\n","\n","conv_layers = EfficientNetB2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","conv_layers.trainable = False\n","\n","model = keras.Sequential()\n","\n","# model.add(conv_layers)\n","model.add(Input((224,224,3)))\n","model.add(Conv2D(64, (3,3), padding='same'))\n","model.add(Conv2D(64, (3,3), padding='same'))\n","model.add(MaxPooling2D())\n","model.add(Conv2D(128, (3,3), padding='same'))\n","model.add(Conv2D(128, (3,3), padding='same'))\n","model.add(MaxPooling2D())\n","model.add(Conv2D(256, (3,3), padding='same'))\n","model.add(Conv2D(256, (3,3), padding='same'))\n","model.add(Conv2D(256, (3,3), padding='same'))\n","model.add(MaxPooling2D())\n","model.add(Conv2D(512, (3,3), padding='same'))\n","model.add(Conv2D(512, (3,3), padding='same'))\n","model.add(Conv2D(512, (3,3), padding='same'))\n","model.add(MaxPooling2D())\n","model.add(Conv2D(512, (3,3), padding='same'))\n","model.add(Conv2D(512, (3,3), padding='same'))\n","model.add(Conv2D(512, (3,3), padding='same'))\n","model.add(MaxPooling2D())\n","model.add(Flatten())\n","model.add(Dense(256, activation='relu'))\n","model.add(Dense(256, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dense(3, activation='softmax'))\n","\n","import tensorflow\n","optimizer = tensorflow.keras.optimizers.RMSprop(learning_rate=0.0001)\n","# model.compile(loss='sparse_categorical_crossentropy', optimizer=\"RMSprop\", metrics=['acc'])  # <-----\n","model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['acc'])\n","model.summary()\n","\n","BATCH_SIZE = 64\n","\n","train_data_generator = ImageDataGenerator(\n","      rotation_range=10,\n","      width_shift_range=0.1,\n","      height_shift_range=0.1,\n","      horizontal_flip=True,\n","      vertical_flip=False,\n","      preprocessing_function=preprocessor\n",").flow_from_directory(\n","      \"glaucoma/train\",\n","      target_size=(224,224),\n","      batch_size=BATCH_SIZE,\n","      class_mode='sparse'\n",")\n","\n","valid_data_generator = ImageDataGenerator(\n","      preprocessing_function=preprocessor\n",").flow_from_directory(\n","      \"glaucoma/valid\",\n","      target_size=(224,224),\n","      batch_size=BATCH_SIZE,\n","      class_mode='sparse'\n",")\n","\n","test_data_generator = ImageDataGenerator(\n","      preprocessing_function=preprocessor\n",").flow_from_directory(\n","      \"glaucoma/test\",\n","      target_size=(224,224),\n","      batch_size=BATCH_SIZE,\n","      class_mode='sparse'\n",")\n","\n","\n","history = model.fit(\n","      train_data_generator,\n","      validation_data=valid_data_generator,\n","      epochs=10\n",")\n","\n","\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.show()\n","\n","\n","loss, acc = model.evaluate(test_data_generator)\n","print(\"loss=\", loss)\n","print(\"acc=\", acc)\n","\n","\n","\n","batch_x, batch_y = test_data_generator.next()\n","y_ = model.predict(batch_x)\n","predicted = np.argmax(y_, axis=-1)\n","\n","plt.plot(batch_y[:100], \"o\")\n","plt.plot(predicted[:100], '.')\n","plt.show()\n","\n","\n","custom_labels = list(test_data_generator.class_indices.keys())\n","print(\"label category index =\", batch_y[0])\n","print(\"predicted category index =\", predicted[0])\n","print(\"predicted category name =\", custom_labels[predicted[0]])\n"],"metadata":{"id":"HZ6AfE8QEVVl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data_generator.batch_size = 1000 # 입력 갯수만큼 받아짐\n","batch_x, batch_y = train_data_generator.next()\n","print(batch_x.shape)\n","print(batch_y.shape)"],"metadata":{"id":"AZm2pvaeEmS9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.hist(batch_y, bins=3)\n","plt.show()"],"metadata":{"id":"91FbMNqPFt_C"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# optimizer 를 Adam으로"],"metadata":{"id":"a4LHzzSEF0yv"}},{"cell_type":"code","source":["from tensorflow.keras.layers import Dropout, Flatten, Dense, BatchNormalization, Conv2D, MaxPooling2D, Input\n","from tensorflow.keras import Model\n","\n","preprocessor = efficientnet.preprocess_input\n","\n","conv_layers = EfficientNetB2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","conv_layers.trainable = False\n","\n","model = keras.Sequential()\n","\n","# model.add(conv_layers)\n","model.add(Input((224,224,3)))\n","model.add(Conv2D(64, (3,3), padding='same'))\n","model.add(Conv2D(64, (3,3), padding='same'))\n","model.add(MaxPooling2D())\n","model.add(Conv2D(128, (3,3), padding='same'))\n","model.add(Conv2D(128, (3,3), padding='same'))\n","model.add(MaxPooling2D())\n","model.add(Conv2D(256, (3,3), padding='same'))\n","model.add(Conv2D(256, (3,3), padding='same'))\n","model.add(Conv2D(256, (3,3), padding='same'))\n","model.add(MaxPooling2D())\n","model.add(Conv2D(512, (3,3), padding='same'))\n","model.add(Conv2D(512, (3,3), padding='same'))\n","model.add(Conv2D(512, (3,3), padding='same'))\n","model.add(MaxPooling2D())\n","model.add(Conv2D(512, (3,3), padding='same'))\n","model.add(Conv2D(512, (3,3), padding='same'))\n","model.add(Conv2D(512, (3,3), padding='same'))\n","model.add(MaxPooling2D())\n","model.add(Flatten())\n","model.add(Dense(256, activation='relu'))\n","model.add(Dense(256, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dense(3, activation='softmax'))\n","\n","import tensorflow\n","optimizer = tensorflow.keras.optimizers.RMSprop(learning_rate=0.0001)\n","# model.compile(loss='sparse_categorical_crossentropy', optimizer=\"RMSprop\", metrics=['acc'])  # <-----\n","model.compile(loss='sparse_categorical_crossentropy', optimizer='Adam', metrics=['acc'])\n","model.summary()\n","\n","BATCH_SIZE = 64\n","\n","train_data_generator = ImageDataGenerator(\n","      rotation_range=10,\n","      width_shift_range=0.1,\n","      height_shift_range=0.1,\n","      horizontal_flip=True,\n","      vertical_flip=False,\n","      preprocessing_function=preprocessor\n",").flow_from_directory(\n","      \"glaucoma/train\",\n","      target_size=(224,224),\n","      batch_size=BATCH_SIZE,\n","      class_mode='sparse'\n",")\n","\n","valid_data_generator = ImageDataGenerator(\n","      preprocessing_function=preprocessor\n",").flow_from_directory(\n","      \"glaucoma/valid\",\n","      target_size=(224,224),\n","      batch_size=BATCH_SIZE,\n","      class_mode='sparse'\n",")\n","\n","test_data_generator = ImageDataGenerator(\n","      preprocessing_function=preprocessor\n",").flow_from_directory(\n","      \"glaucoma/test\",\n","      target_size=(224,224),\n","      batch_size=BATCH_SIZE,\n","      class_mode='sparse'\n",")\n","\n","\n","history = model.fit(\n","      train_data_generator,\n","      validation_data=valid_data_generator,\n","      epochs=10\n",")\n","\n","\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.show()\n","\n","\n","loss, acc = model.evaluate(test_data_generator)\n","print(\"loss=\", loss)\n","print(\"acc=\", acc)\n","\n","\n","\n","batch_x, batch_y = test_data_generator.next()\n","y_ = model.predict(batch_x)\n","predicted = np.argmax(y_, axis=-1)\n","\n","plt.plot(batch_y[:100], \"o\")\n","plt.plot(predicted[:100], '.')\n","plt.show()\n","\n","\n","custom_labels = list(test_data_generator.class_indices.keys())\n","print(\"label category index =\", batch_y[0])\n","print(\"predicted category index =\", predicted[0])\n","print(\"predicted category name =\", custom_labels[predicted[0]])\n"],"metadata":{"id":"dIGelDfkGOha"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# epoch 을 더 많이 학습"],"metadata":{"id":"ozSQFtdcGT03"}},{"cell_type":"code","source":["history = model.fit(\n","      train_data_generator,\n","      validation_data=valid_data_generator,\n","      epochs=40\n",")\n","\n","\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.show()\n","\n","\n","loss, acc = model.evaluate(test_data_generator)\n","print(\"loss=\", loss)\n","print(\"acc=\", acc)\n","\n","\n","\n","batch_x, batch_y = test_data_generator.next()\n","y_ = model.predict(batch_x)\n","predicted = np.argmax(y_, axis=-1)\n","\n","plt.plot(batch_y[:100], \"o\")\n","plt.plot(predicted[:100], '.')\n","plt.show()\n","\n","\n","custom_labels = list(test_data_generator.class_indices.keys())\n","print(\"label category index =\", batch_y[0])\n","print(\"predicted category index =\", predicted[0])\n","print(\"predicted category name =\", custom_labels[predicted[0]])\n"],"metadata":{"id":"4sJStgPvHMtX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Conv 레이어들 작게 조정"],"metadata":{"id":"6uJwXQ2-KJKd"}},{"cell_type":"code","source":["import os\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","from tensorflow import keras\n","from tensorflow.keras import optimizers\n","from tensorflow.keras import models\n","from tensorflow.keras import layers\n","from tensorflow.keras import optimizers\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dropout, Flatten, Dense, BatchNormalization, Conv2D, MaxPooling2D, Input\n","from tensorflow.keras import Model\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.preprocessing.image import load_img\n","from tensorflow.keras.preprocessing.image import img_to_array\n","\n","from tensorflow.keras.applications import efficientnet\n","from tensorflow.keras.applications import EfficientNetB2\n","\n","preprocessor = efficientnet.preprocess_input\n","\n","# conv_layers = EfficientNetB2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","# conv_layers.trainable = True\n","\n","model = keras.Sequential()\n","\n","# model.add(conv_layers)\n","model.add(Input((224,224,3)))\n","model.add(Conv2D(32, (3,3), padding='same'))   # <-----------------------\n","model.add(Conv2D(32, (3,3), padding='same'))   # <-----------------------\n","model.add(Conv2D(32, (3,3), padding='same'))   # <-----------------------\n","model.add(MaxPooling2D())\n","model.add(Conv2D(32, (3,3), padding='same'))   # <-----------------------\n","model.add(Conv2D(32, (3,3), padding='same'))   # <-----------------------\n","model.add(Conv2D(32, (3,3), padding='same'))   # <-----------------------\n","model.add(MaxPooling2D())\n","model.add(Conv2D(64, (3,3), padding='same'))   # <-----------------------\n","model.add(Conv2D(64, (3,3), padding='same'))   # <-----------------------\n","model.add(Conv2D(64, (3,3), padding='same'))   # <-----------------------\n","model.add(MaxPooling2D())\n","model.add(Conv2D(128, (3,3), padding='same'))   # <-----------------------\n","model.add(Conv2D(128, (3,3), padding='same'))   # <-----------------------\n","model.add(Conv2D(128, (3,3), padding='same'))   # <-----------------------\n","model.add(MaxPooling2D())\n","model.add(Conv2D(128, (3,3), padding='same'))   # <-----------------------\n","model.add(Conv2D(128, (3,3), padding='same'))   # <-----------------------\n","model.add(Conv2D(128, (3,3), padding='same'))   # <-----------------------\n","model.add(MaxPooling2D())\n","model.add(Flatten())\n","model.add(Dense(256, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dense(3, activation='softmax'))\n","\n","import tensorflow\n","optimizer = tensorflow.keras.optimizers.Adam(learning_rate=0.0001)\n","# model.compile(loss='sparse_categorical_crossentropy', optimizer=\"RMSprop\", metrics=['acc'])\n","model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['acc'])\n","model.summary()\n","\n","BATCH_SIZE = 64\n","\n","train_data_generator = ImageDataGenerator(\n","      rotation_range=10,\n","      width_shift_range=0.1,\n","      height_shift_range=0.1,\n","      horizontal_flip=True,\n","      vertical_flip=False,\n","      preprocessing_function=preprocessor\n",").flow_from_directory(\n","      \"glaucoma/train\",\n","      target_size=(224,224),\n","      batch_size=BATCH_SIZE,\n","      class_mode='sparse'\n",")\n","\n","valid_data_generator = ImageDataGenerator(\n","      preprocessing_function=preprocessor\n",").flow_from_directory(\n","      \"glaucoma/valid\",\n","      target_size=(224,224),\n","      batch_size=BATCH_SIZE,\n","      class_mode='sparse'\n",")\n","\n","test_data_generator = ImageDataGenerator(\n","      preprocessing_function=preprocessor\n",").flow_from_directory(\n","      \"glaucoma/test\",\n","      target_size=(224,224),\n","      batch_size=BATCH_SIZE,\n","      class_mode='sparse'\n",")\n","\n","\n","history = model.fit(\n","      train_data_generator,\n","      validation_data=valid_data_generator,\n","      epochs=10\n",")\n","\n","\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.show()\n","\n","plt.plot(history.history['acc'])\n","plt.plot(history.history['val_acc'])\n","plt.show()\n","\n","loss, acc = model.evaluate(test_data_generator)\n","print(\"loss=\", loss)\n","print(\"acc=\", acc)\n","\n","\n","\n","batch_x, batch_y = test_data_generator.next()\n","y_ = model.predict(batch_x)\n","predicted = np.argmax(y_, axis=-1)\n","\n","plt.plot(batch_y[:100], \"o\")\n","plt.plot(predicted[:100], '.')\n","plt.show()\n","\n","\n","custom_labels = list(test_data_generator.class_indices.keys())\n","print(\"label category index =\", batch_y[0])\n","print(\"predicted category index =\", predicted[0])\n","print(\"predicted category name =\", custom_labels[predicted[0]])\n"],"metadata":{"id":"kVX-1icCKAqL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"sFqe-2QtKbnW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Conv 더 작게"],"metadata":{"id":"CEdsfZrmLIKH"}},{"cell_type":"code","source":["import os\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","from tensorflow import keras\n","from tensorflow.keras import optimizers\n","from tensorflow.keras import models\n","from tensorflow.keras import layers\n","from tensorflow.keras import optimizers\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dropout, Flatten, Dense, BatchNormalization, Conv2D, MaxPooling2D, Input\n","from tensorflow.keras import Model\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.preprocessing.image import load_img\n","from tensorflow.keras.preprocessing.image import img_to_array\n","\n","from tensorflow.keras.applications import efficientnet\n","from tensorflow.keras.applications import EfficientNetB2\n","\n","preprocessor = efficientnet.preprocess_input\n","\n","# conv_layers = EfficientNetB2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","# conv_layers.trainable = True\n","\n","model = keras.Sequential()\n","\n","# model.add(conv_layers)\n","model.add(Input((224,224,3)))\n","model.add(Conv2D(32, (3,3), padding='same'))\n","model.add(Conv2D(32, (3,3), padding='same'))\n","model.add(Conv2D(32, (3,3), padding='same'))\n","model.add(MaxPooling2D())\n","model.add(Conv2D(32, (3,3), padding='same'))   # <-----------------------\n","model.add(Conv2D(32, (3,3), padding='same'))   # <-----------------------\n","model.add(Conv2D(32, (3,3), padding='same'))   # <-----------------------\n","model.add(MaxPooling2D())\n","model.add(Conv2D(64, (3,3), padding='same'))   # <-----------------------\n","model.add(Conv2D(64, (3,3), padding='same'))   # <-----------------------\n","model.add(Conv2D(64, (3,3), padding='same'))   # <-----------------------\n","model.add(MaxPooling2D())\n","model.add(Conv2D(64, (3,3), padding='same'))   # <-----------------------\n","model.add(Conv2D(64, (3,3), padding='same'))   # <-----------------------\n","model.add(Conv2D(64, (3,3), padding='same'))   # <-----------------------\n","model.add(MaxPooling2D())\n","model.add(Conv2D(64, (3,3), padding='same'))   # <-----------------------\n","model.add(Conv2D(64, (3,3), padding='same'))   # <-----------------------\n","model.add(Conv2D(64, (3,3), padding='same'))   # <-----------------------\n","model.add(MaxPooling2D())\n","model.add(Flatten())\n","model.add(Dense(256, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dense(3, activation='softmax'))\n","\n","import tensorflow\n","optimizer = tensorflow.keras.optimizers.Adam(learning_rate=0.0001)\n","# model.compile(loss='sparse_categorical_crossentropy', optimizer=\"RMSprop\", metrics=['acc'])\n","model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['acc'])\n","model.summary()\n","\n","BATCH_SIZE = 64\n","\n","train_data_generator = ImageDataGenerator(\n","      rotation_range=10,\n","      width_shift_range=0.1,\n","      height_shift_range=0.1,\n","      horizontal_flip=True,\n","      vertical_flip=False,\n","      preprocessing_function=preprocessor\n",").flow_from_directory(\n","      \"glaucoma/train\",\n","      target_size=(224,224),\n","      batch_size=BATCH_SIZE,\n","      class_mode='sparse'\n",")\n","\n","valid_data_generator = ImageDataGenerator(\n","      preprocessing_function=preprocessor\n",").flow_from_directory(\n","      \"glaucoma/valid\",\n","      target_size=(224,224),\n","      batch_size=BATCH_SIZE,\n","      class_mode='sparse'\n",")\n","\n","test_data_generator = ImageDataGenerator(\n","      preprocessing_function=preprocessor\n",").flow_from_directory(\n","      \"glaucoma/test\",\n","      target_size=(224,224),\n","      batch_size=BATCH_SIZE,\n","      class_mode='sparse'\n",")\n","\n","\n","history = model.fit(\n","      train_data_generator,\n","      validation_data=valid_data_generator,\n","      epochs=10\n",")\n","\n","\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.show()\n","\n","plt.plot(history.history['acc'])\n","plt.plot(history.history['val_acc'])\n","plt.show()\n","\n","loss, acc = model.evaluate(test_data_generator)\n","print(\"loss=\", loss)\n","print(\"acc=\", acc)\n","\n","\n","\n","batch_x, batch_y = test_data_generator.next()\n","y_ = model.predict(batch_x)\n","predicted = np.argmax(y_, axis=-1)\n","\n","plt.plot(batch_y[:100], \"o\")\n","plt.plot(predicted[:100], '.')\n","plt.show()\n","\n","\n","custom_labels = list(test_data_generator.class_indices.keys())\n","print(\"label category index =\", batch_y[0])\n","print(\"predicted category index =\", predicted[0])\n","print(\"predicted category name =\", custom_labels[predicted[0]])\n"],"metadata":{"id":"AEUMgpBhLKD_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 사용하면 안될 preprocess를 제거하고 scaling"],"metadata":{"id":"ggL6vnCiMOX8"}},{"cell_type":"code","source":["train_data_generator.batch_size=32\n","batch_x, batch_y = train_data_generator.next()\n","print(batch_x.shape)\n","print(batch_y.shape)\n","\n","plt.hist(batch_x[0].flatten(), bins=1000)\n","plt.show()"],"metadata":{"id":"rKz9Pj-8LS6f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","from tensorflow import keras\n","from tensorflow.keras import optimizers\n","from tensorflow.keras import models\n","from tensorflow.keras import layers\n","from tensorflow.keras import optimizers\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dropout, Flatten, Dense, BatchNormalization, Conv2D, MaxPooling2D, Input\n","from tensorflow.keras import Model\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.preprocessing.image import load_img\n","from tensorflow.keras.preprocessing.image import img_to_array\n","\n","from tensorflow.keras.applications import efficientnet\n","from tensorflow.keras.applications import EfficientNetB2\n","\n","preprocessor = efficientnet.preprocess_input\n","\n","# conv_layers = EfficientNetB2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","# conv_layers.trainable = True\n","\n","model = keras.Sequential()\n","\n","# model.add(conv_layers)\n","model.add(Input((224,224,3)))\n","model.add(Conv2D(32, (3,3), padding='same'))\n","model.add(Conv2D(32, (3,3), padding='same'))\n","model.add(Conv2D(32, (3,3), padding='same'))\n","model.add(MaxPooling2D())\n","model.add(Conv2D(32, (3,3), padding='same'))\n","model.add(Conv2D(32, (3,3), padding='same'))\n","model.add(Conv2D(32, (3,3), padding='same'))\n","model.add(MaxPooling2D())\n","model.add(Conv2D(64, (3,3), padding='same'))\n","model.add(Conv2D(64, (3,3), padding='same'))\n","model.add(Conv2D(64, (3,3), padding='same'))\n","model.add(MaxPooling2D())\n","model.add(Conv2D(64, (3,3), padding='same'))\n","model.add(Conv2D(64, (3,3), padding='same'))\n","model.add(Conv2D(64, (3,3), padding='same'))\n","model.add(MaxPooling2D())\n","model.add(Conv2D(64, (3,3), padding='same'))\n","model.add(Conv2D(64, (3,3), padding='same'))\n","model.add(Conv2D(64, (3,3), padding='same'))\n","model.add(MaxPooling2D())\n","model.add(Flatten())\n","model.add(Dense(256, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dense(3, activation='softmax'))\n","\n","import tensorflow\n","optimizer = tensorflow.keras.optimizers.Adam(learning_rate=0.0001)\n","# model.compile(loss='sparse_categorical_crossentropy', optimizer=\"RMSprop\", metrics=['acc'])\n","model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['acc'])\n","model.summary()\n","\n","BATCH_SIZE = 64\n","\n","train_data_generator = ImageDataGenerator(\n","      rotation_range=10,\n","      width_shift_range=0.1,\n","      height_shift_range=0.1,\n","      horizontal_flip=True,\n","      vertical_flip=False,\n","      rescale=1/255.,   # <-----------------------\n","      # preprocessing_function=preprocessor   # <-----------------------\n",").flow_from_directory(\n","      \"glaucoma/train\",\n","      target_size=(224,224),\n","      batch_size=BATCH_SIZE,\n","      class_mode='sparse'\n",")\n","\n","valid_data_generator = ImageDataGenerator(\n","      rescale=1/255.,\n","      # preprocessing_function=preprocessor   # <-----------------------\n",").flow_from_directory(\n","      \"glaucoma/valid\",\n","      target_size=(224,224),\n","      batch_size=BATCH_SIZE,\n","      class_mode='sparse'\n",")\n","\n","test_data_generator = ImageDataGenerator(\n","      rescale=1/255.,\n","      # preprocessing_function=preprocessor   # <-----------------------\n",").flow_from_directory(\n","      \"glaucoma/test\",\n","      target_size=(224,224),\n","      batch_size=BATCH_SIZE,\n","      class_mode='sparse'\n",")\n","\n","\n","history = model.fit(\n","      train_data_generator,\n","      validation_data=valid_data_generator,\n","      epochs=10\n",")\n","\n","\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.show()\n","\n","plt.plot(history.history['acc'])\n","plt.plot(history.history['val_acc'])\n","plt.show()\n","\n","loss, acc = model.evaluate(test_data_generator)\n","print(\"loss=\", loss)\n","print(\"acc=\", acc)\n","\n","\n","\n","batch_x, batch_y = test_data_generator.next()\n","y_ = model.predict(batch_x)\n","predicted = np.argmax(y_, axis=-1)\n","\n","plt.plot(batch_y[:100], \"o\")\n","plt.plot(predicted[:100], '.')\n","plt.show()\n","\n","\n","custom_labels = list(test_data_generator.class_indices.keys())\n","print(\"label category index =\", batch_y[0])\n","print(\"predicted category index =\", predicted[0])\n","print(\"predicted category name =\", custom_labels[predicted[0]])\n"],"metadata":{"id":"pNRevCAvMhto"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data_generator.batch_size=32\n","batch_x, batch_y = train_data_generator.next()\n","print(batch_x.shape)\n","print(batch_y.shape)\n","\n","plt.hist(batch_x[0].flatten(), bins=1000)\n","plt.show()"],"metadata":{"id":"oObb3Ua4M68_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["BATCH_SIZE = 16\n","\n","train_data_generator = ImageDataGenerator(\n","      rotation_range=10,\n","      width_shift_range=0.1,\n","      height_shift_range=0.1,\n","      horizontal_flip=True,\n","      vertical_flip=False,\n","      rescale=1/255.,\n","      # preprocessing_function=preprocessor\n",").flow_from_directory(\n","      \"glaucoma/train\",\n","      target_size=(224,224),\n","      batch_size=BATCH_SIZE,\n","      class_mode='sparse'\n",")\n","\n","valid_data_generator = ImageDataGenerator(\n","      rescale=1/255.,\n","      # preprocessing_function=preprocessor\n",").flow_from_directory(\n","      \"glaucoma/valid\",\n","      target_size=(224,224),\n","      batch_size=BATCH_SIZE,\n","      class_mode='sparse'\n",")\n","\n","\n","history = model.fit(\n","      train_data_generator,\n","      validation_data=valid_data_generator,\n","      epochs=3\n",")"],"metadata":{"id":"J4Nw32kvN9rh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Learning_Rate 줄이고 epoch 수 많이"],"metadata":{"id":"LcLqWjcWOt3Y"}},{"cell_type":"code","source":["import os\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","from tensorflow import keras\n","from tensorflow.keras import optimizers\n","from tensorflow.keras import models\n","from tensorflow.keras import layers\n","from tensorflow.keras import optimizers\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dropout, Flatten, Dense, BatchNormalization, Conv2D, MaxPooling2D, Input\n","from tensorflow.keras import Model\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.preprocessing.image import load_img\n","from tensorflow.keras.preprocessing.image import img_to_array\n","\n","from tensorflow.keras.applications import efficientnet\n","from tensorflow.keras.applications import EfficientNetB2\n","\n","preprocessor = efficientnet.preprocess_input\n","\n","# conv_layers = EfficientNetB2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","# conv_layers.trainable = True\n","\n","model = keras.Sequential()\n","\n","# model.add(conv_layers)\n","model.add(Input((224,224,3)))\n","model.add(Conv2D(32, (3,3), padding='same'))\n","model.add(Conv2D(32, (3,3), padding='same'))\n","model.add(Conv2D(32, (3,3), padding='same'))\n","model.add(MaxPooling2D())\n","model.add(Conv2D(32, (3,3), padding='same'))\n","model.add(Conv2D(32, (3,3), padding='same'))\n","model.add(Conv2D(32, (3,3), padding='same'))\n","model.add(MaxPooling2D())\n","model.add(Conv2D(64, (3,3), padding='same'))\n","model.add(Conv2D(64, (3,3), padding='same'))\n","model.add(Conv2D(64, (3,3), padding='same'))\n","model.add(MaxPooling2D())\n","model.add(Conv2D(64, (3,3), padding='same'))\n","model.add(Conv2D(64, (3,3), padding='same'))\n","model.add(Conv2D(64, (3,3), padding='same'))\n","model.add(MaxPooling2D())\n","model.add(Conv2D(64, (3,3), padding='same'))\n","model.add(Conv2D(64, (3,3), padding='same'))\n","model.add(Conv2D(64, (3,3), padding='same'))\n","model.add(MaxPooling2D())\n","model.add(Flatten())\n","model.add(Dense(256, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dense(3, activation='softmax'))\n","\n","import tensorflow\n","optimizer = tensorflow.keras.optimizers.Adam(learning_rate=0.0001*0.1)  # <-----------------------\n","# model.compile(loss='sparse_categorical_crossentropy', optimizer=\"RMSprop\", metrics=['acc'])\n","model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['acc'])\n","model.summary()\n","\n","BATCH_SIZE = 64\n","\n","train_data_generator = ImageDataGenerator(\n","      rotation_range=10,\n","      width_shift_range=0.1,\n","      height_shift_range=0.1,\n","      horizontal_flip=True,\n","      vertical_flip=False,\n","      rescale=1/255.,\n","      # preprocessing_function=preprocessor \n",").flow_from_directory(\n","      \"glaucoma/train\",\n","      target_size=(224,224),\n","      batch_size=BATCH_SIZE,\n","      class_mode='sparse'\n",")\n","\n","valid_data_generator = ImageDataGenerator(\n","      rescale=1/255.\n","      # preprocessing_function=preprocessor \n",").flow_from_directory(\n","      \"glaucoma/valid\",\n","      target_size=(224,224),\n","      batch_size=BATCH_SIZE,\n","      class_mode='sparse'\n",")\n","\n","test_data_generator = ImageDataGenerator(\n","      rescale=1/255., \n","      # preprocessing_function=preprocessor\n",").flow_from_directory(\n","      \"glaucoma/test\",\n","      target_size=(224,224),\n","      batch_size=BATCH_SIZE,\n","      class_mode='sparse'\n",")\n","\n","\n","history = model.fit(\n","      train_data_generator,\n","      validation_data=valid_data_generator,\n","      epochs=40  # <-----------------------\n",")\n","\n","\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.show()\n","\n","plt.plot(history.history['acc'])\n","plt.plot(history.history['val_acc'])\n","plt.show()\n","\n","loss, acc = model.evaluate(test_data_generator)\n","print(\"loss=\", loss)\n","print(\"acc=\", acc)\n","\n","\n","\n","batch_x, batch_y = test_data_generator.next()\n","y_ = model.predict(batch_x)\n","predicted = np.argmax(y_, axis=-1)\n","\n","plt.plot(batch_y[:100], \"o\")\n","plt.plot(predicted[:100], '.')\n","plt.show()\n","\n","\n","custom_labels = list(test_data_generator.class_indices.keys())\n","print(\"label category index =\", batch_y[0])\n","print(\"predicted category index =\", predicted[0])\n","print(\"predicted category name =\", custom_labels[predicted[0]])\n"],"metadata":{"id":"tkWPkcOCQuON"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"lqtv0lTmQ7y5"},"execution_count":null,"outputs":[]}]}